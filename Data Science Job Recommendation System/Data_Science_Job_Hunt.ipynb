{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from pyresparser import ResumeParser\n",
    "import PyPDF2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import scattertext as st\n",
    "# from pandas import json_normalize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import spacy\n",
    "# import texthero as hero\n",
    "# from wordcloud import WordCloud\n",
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979bff8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# df['jd_text'] = df['Job Description'].pipe(hero.clean)\n",
    "# text = \" \".join(df['jd_text'].values)\n",
    "\n",
    "# def make_wordcloud(text):\n",
    "\n",
    "#     wordcloud = WordCloud(\n",
    "#         width=800,\n",
    "#         height=800,\n",
    "#         min_font_size=10,\n",
    "#         background_color=\"black\",\n",
    "#         colormap=\"Set2\",\n",
    "#         collocation_threshold=3,\n",
    "#     ).generate(text)\n",
    "\n",
    "#     fig = plt.figure(figsize=(8, 8), facecolor=None)\n",
    "#     plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.tight_layout(pad=0)\n",
    "#     plt.show()\n",
    "#     return fig\n",
    "\n",
    "# text_cloud = make_wordcloud(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d61d2c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "# filtered_df = df.copy()\n",
    "# filtered_df[\"parse\"] = filtered_df['Job Description'].apply(st.whitespace_nlp_with_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36b7d9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# corpus = (\n",
    "#     st.CorpusFromParsedDocuments(filtered_df, category_col=\"job_title_category\", parsed_col=\"parse\")\n",
    "#     .build()\n",
    "#     .get_unigram_corpus()\n",
    "#     .compact(st.AssociationCompactor(2000))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242fea50",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# used for tagging words with their parts of speech\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "# term_freq_df = corpus.get_term_freq_df()\n",
    "# term_freq_df[\"data_scientist_score\"] = corpus.get_scaled_f_scores(\"data_scientist\")\n",
    "# term_freq_df[\"data_analyst_score\"] = corpus.get_scaled_f_scores(\"data_analyst\")\n",
    "# term_freq_df[\"data_engineer_score\"] = corpus.get_scaled_f_scores(\"data_engineer\")\n",
    "# term_freq_df[\"ml_engineer_score\"] = corpus.get_scaled_f_scores(\"ml_engineer\")\n",
    "# term_freq_df[\"others_score\"] = corpus.get_scaled_f_scores(\"others\")\n",
    "\n",
    "# # Remove terms that are not nouns\n",
    "# def is_noun(word: str):\n",
    "#     pos = nltk.pos_tag([word])[0][1]\n",
    "#     return pos[:2] == \"NN\"\n",
    "\n",
    "# term_freq_df = term_freq_df.loc[map(is_noun, term_freq_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf99afe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# term_freq_df.sort_values(by='data_scientist_score', ascending=False).index[:30]\n",
    "# term_freq_df.sort_values(by='data_analyst_score', ascending=False).index[:30]\n",
    "# term_freq_df.sort_values(by='data_engineer_score', ascending=False).index[:30]\n",
    "# term_freq_df.sort_values(by='ml_engineer_score', ascending=False).index[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a15344",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# url = \"https://auth.emsicloud.com/connect/token\"\n",
    "# CLIENT_ID = 'guntc5o6ib9mqb8x'\n",
    "# CLIENT_SECRET = '0ItWAUes'\n",
    "\n",
    "# payload = \"client_id=\" + CLIENT_ID + \"&client_secret=\" + CLIENT_SECRET + \"&grant_type=client_credentials&scope=emsi_open\"\n",
    "# headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "# response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "# access_token = json.loads(response.text)['access_token']\n",
    "# print(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e9459",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# url = \"https://emsiservices.com/skills/versions/latest/skills\"\n",
    "# auth = 'Bearer ' + access_token \n",
    "# headers = {'Authorization': auth}\n",
    "# querystring = {\"fields\": \"name, type\"}\n",
    "# response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "# response = response.json()['data']\n",
    "# all_skills_df = pd.DataFrame(json_normalize(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ac3da",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# all_skills_df = all_skills_df[all_skills_df['type.name'] == 'Hard Skill']\n",
    "# all_skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be393c2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# all_skills_df = pd.read_csv('all_skills_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6135a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# all_skills_df['name'] = all_skills_df['name'].str.lower()\n",
    "# all_skills_df['name'] = all_skills_df['name'].apply(lambda x: x.split())\n",
    "# all_skills_df = all_skills_df.explode('name')\n",
    "# all_skills = set(all_skills_df['name'])\n",
    "# print(all_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b0219",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# skills = []\n",
    "# for word in text:\n",
    "#     if word in all_skills and len(word) > 1 and not word.isdigit():\n",
    "#         skills.append(word)\n",
    "# print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49dc63",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# en = spacy.load('en_core_web_sm')\n",
    "# sw_spacy = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27347774",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# new_skill_list = [word for word in skills if word not in sw_spacy]\n",
    "# print(new_skill_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46730497",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# skill_set = set()\n",
    "# nltk.download('wordnet')\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# for word in new_skill_list:\n",
    "#     skill_set.add(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ec0e8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# text_2 = \" \".join(text)\n",
    "# text_file = open('text.txt', 'w')\n",
    "# _ = text_file.write(text_2)\n",
    "# text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64483c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from resume_parser import resumeparse\n",
    "# data_2 = resumeparse.read_file('check.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4fe64",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from pyresparser import ResumeParser\n",
    "# data = ResumeParser('check.docx').get_extracted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677006c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_title_category'] = df['Job Title'].apply(lambda x: \n",
    "    'data_engineer' if 'intelligence anal' in x.lower()\n",
    "    else 'data_engineer' if 'data engineer' in x.lower()\n",
    "    else 'ml_engineer' if 'machine learning' in x.lower()\n",
    "    else 'data_scientist' if 'data scien' in x.lower()\n",
    "    else 'data_analyst' if 'anal' in x.lower()\n",
    "    else 'unknown')\n",
    "job_titles = list(df['job_title_category'].unique())\n",
    "print(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Degree'] = df['Degree'].replace({'na': 'B'})\n",
    "df['Degree'] = df['Degree'].apply(lambda x: ['B', 'M', 'P'] if x == 'P' else ['B', 'M'] if x == 'M' else ['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKILLS_DB = ['data-science', 'machine-learning', 'cloud', 'database-management', 'bigdata',\n",
    "             'data-analytics', 'business-intelligence', 'analytics', 'statistics', 'data-visualization']\n",
    "skills_stack_overflow = []\n",
    "for skills in SKILLS_DB:\n",
    "    url = \"https://api.stackexchange.com/2.3/tags/\" + skills + \"/related?site=stackoverflow\"\n",
    "    response = requests.request(\"GET\", url)\n",
    "    response = json.loads(response.text)\n",
    "    time.sleep(3)\n",
    "    for i in range(len(response['items'])):\n",
    "        skills_stack_overflow.append(response['items'][i]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62849945",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKILLS_DB.extend(['aws', 'gcp', 'spark', 'bi', 'tableau', 'clustering', 'recommendation', \n",
    "                  'rnn', 'recurringneuralnetwork', 'cnn', 'redshift', 'kafka', 'redis', 'sas', \n",
    "                  'bayesian', 'bayesiananalysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff40239",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_stack_overflow.extend(SKILLS_DB)\n",
    "skills_stack_overflow = list(set(skills_stack_overflow))\n",
    "skills_stack_overflow = [x.replace('-', '') for x in skills_stack_overflow]\n",
    "skills_stack_overflow = set(skills_stack_overflow)\n",
    "skills_stack_overflow = skills_stack_overflow - set(['charts', 'visualization', 'plot', 'csv', 'ios', 'logging', \n",
    "                                                    'random', 'businessobjects', 'facebook', 'android', 'dataset', \n",
    "                                                    'report', 'server', 'parseplatform', 'tracking', 'performance'])\n",
    "print(sorted(list(skills_stack_overflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = set()\n",
    "jd = df['Job Description']\n",
    "df['skills'] = np.empty((len(df), 0)).tolist()\n",
    "char_to_int = {'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10, \n",
    "              'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14, 'fifteen': 15, 'sixteen': 16}\n",
    "df['experience'] = 'Unknown'\n",
    "for i in range(len(jd)):\n",
    "    temp = set()\n",
    "    text = jd[i]\n",
    "    text = text.lower()\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    text = tokenizer.tokenize(text)\n",
    "    for word in text:\n",
    "        if word in skills_stack_overflow and word not in temp:\n",
    "                skills.add(word)\n",
    "                temp.add(word)\n",
    "    bigrams = list(map(' '.join, nltk.everygrams(text, 2, 2)))\n",
    "    bigrams = [x.replace(' ', '') for x in bigrams]\n",
    "    for bigram in bigrams:\n",
    "        if bigram in skills_stack_overflow and bigram not in temp:\n",
    "            skills.add(bigram)\n",
    "            temp.add(bigram)\n",
    "    if len(temp) < 5:\n",
    "        df['skills'][i] = ['Unknown']\n",
    "    else:\n",
    "        df['skills'][i].extend(temp)\n",
    "    text = \" \".join(text)\n",
    "    text_copy = text\n",
    "    start_idx = text.find('qualification')\n",
    "    if start_idx == -1:\n",
    "        start_idx = text.find('requirements')\n",
    "    if start_idx != -1:\n",
    "        text = text[start_idx:]\n",
    "    end_idx = text.find('experience') + 40\n",
    "    if start_idx == -1 and end_idx == 39:\n",
    "        pass\n",
    "    else: \n",
    "        text = text[:end_idx + 1]\n",
    "    rx = re.compile('\\w+(?=\\s+year)')\n",
    "    is_found = rx.search(text)\n",
    "    if is_found:\n",
    "        match = is_found.group(0)\n",
    "        if match in char_to_int:\n",
    "            exp = char_to_int[match]\n",
    "            if exp <= 2:\n",
    "                exp = 'Entry'\n",
    "            elif exp < 5:\n",
    "                exp = 'Mid'\n",
    "            elif exp <= 16:\n",
    "                exp = 'Senior'\n",
    "            df['experience'][i] = exp\n",
    "        elif match.isdigit():\n",
    "            exp = int(match)\n",
    "            if exp <= 2:\n",
    "                exp = 'Entry'\n",
    "            elif exp < 5:\n",
    "                exp = 'Mid'\n",
    "            elif exp <= 15:\n",
    "                exp = 'Senior'\n",
    "            if type(exp) == str:\n",
    "                df['experience'][i] = exp\n",
    "    else:\n",
    "        experience_types = ['years of experience', 'years experience', 'years relevant experience', \n",
    "                           'years professional experience']\n",
    "        flag = False\n",
    "        for experience_type in experience_types:\n",
    "            rx = re.compile('\\w+(?=\\s+' + experience_type + ')')\n",
    "            is_found = rx.search(text_copy)\n",
    "            if is_found:\n",
    "                match = is_found.group(0)\n",
    "                if match in char_to_int:\n",
    "                    exp = char_to_int[match]\n",
    "                    if exp <= 2:\n",
    "                        exp = 'Entry'\n",
    "                    elif exp <= 5:\n",
    "                        exp = 'Mid'\n",
    "                    elif exp <= 15:\n",
    "                        exp = 'Senior'\n",
    "                    df['experience'][i] = exp\n",
    "                    flag = True\n",
    "                    break\n",
    "                elif match.isdigit():\n",
    "                    exp = int(match)\n",
    "                    if exp <= 2:\n",
    "                        exp = 'Entry'\n",
    "                    elif exp <= 5:\n",
    "                        exp = 'Mid'\n",
    "                    elif exp <= 15:\n",
    "                        exp = 'Senior'\n",
    "                    if type(exp) == str:\n",
    "                        df['experience'][i] = exp\n",
    "                        flag = True\n",
    "                        break\n",
    "        if not flag:\n",
    "            job_title = df['Job Title'][i].lower()\n",
    "            if 'manage' in job_title or 'direct' in job_title or 'principal' in job_title or 'lead' in job_title or 'architect' in job_title or 'project' in job_title or 'staff' in job_title:\n",
    "                exp = 'Senior'\n",
    "                df['experience'][i] = exp\n",
    "            elif 'associate' in job_title or 'sr' in job_title or 'senior' in job_title or 'consult' in job_title or ' ii' or job_title:\n",
    "                exp = 'Mid'\n",
    "                df['experience'][i] = exp\n",
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b201463",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df['skill_len'] = df['skills'].apply(lambda x: len(x))\n",
    "df = df[df['skill_len'] != 1]\n",
    "salary_df = df.copy()\n",
    "salary_df.to_csv('salary_df.csv', index=False)\n",
    "df = df.reset_index()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2307c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = list(df['Sector'].unique())\n",
    "sector_og = sectors.copy()\n",
    "sectors.extend(['marketing', 'fashion', 'civil', 'construction', 'entertainment', 'art', 'oil', 'energy', 'supplychain', \n",
    "               'educationdepartment', 'educationsector', 'educationindustry'])\n",
    "sectors = [x.lower() for x in sectors]\n",
    "sectors = [x.split(' & ') for x in sectors]\n",
    "sectors = [item for sublist in sectors for item in sublist]\n",
    "sectors = [x.replace(',', '') for x in sectors]\n",
    "sectors = [x.replace(' ', '') for x in sectors]\n",
    "sectors.remove('utilities')\n",
    "sectors.remove('artsentertainment')\n",
    "sectors.remove('oilgasenergy')\n",
    "sectors.remove('informationtechnology')\n",
    "sectors.remove('education')\n",
    "sectors.remove('-1')\n",
    "sectors = [re.sub('s$', '', x) for x in sectors]\n",
    "sectors_dict = {}\n",
    "for sector in sectors:\n",
    "    if sector == 'aerospace':\n",
    "        sectors_dict[sector] = 'defence'\n",
    "    elif sector == 'oil':\n",
    "        sectors_dict[sector] = 'energy'\n",
    "    elif sector == 'finance' or sector == 'insurance' or sector == 'accounting':\n",
    "        sectors_dict[sector] = 'banking'\n",
    "    elif sector == 'biotech' or sector == 'pharmaceutical':\n",
    "        sectors_dict[sector] = 'healthcare'\n",
    "    elif sector == 'media':\n",
    "        sectors_dict[sector] = 'marketing'\n",
    "    elif sector == 'logistic' or sector == 'supplychain':\n",
    "        sectors_dict['logistics'] = 'transportation'\n",
    "    elif sector == 'metal':\n",
    "        sectors_dict[sector] = 'mining'\n",
    "    elif sector == 'tourism':\n",
    "        sectors_dict[sector] = 'travel'\n",
    "    elif sector == 'non-profit':\n",
    "        sectors_dict[sector] = 'government'\n",
    "    elif sector == 'recreation' or sector == 'fashion' or sector == 'art':\n",
    "        sectors_dict[sector] = 'entertainment'\n",
    "    elif sector == 'construction':\n",
    "        sectors_dict[sector] = 'civil'\n",
    "    elif sector == 'educationdepartment' or sector == 'educationsector' or sector == 'educationindustry':\n",
    "        sectors_dict[sector] = 'education'\n",
    "    elif sector == 'forestry':\n",
    "        sectors_dict[sector] = 'agriculture'\n",
    "    else:\n",
    "        sectors_dict[sector] = sector\n",
    "print(sectors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sector_category'] = df['Sector'].str.lower()\n",
    "df['sector_category'] = df['sector_category'].apply(lambda x: x.replace(' & ', ''))\n",
    "df['sector_category'] = df['sector_category'].apply(lambda x: x.replace(',', ''))\n",
    "df['sector_category'] = df['sector_category'].apply(lambda x: x.replace(' ', ''))\n",
    "df['sector_category'] = df['sector_category'].apply(lambda x:\n",
    "    'defence' if 'defense' in x\n",
    "    else 'energy' if 'energy' in x \n",
    "    else 'banking' if 'finance' in x\n",
    "    else 'healthcare' if 'pharma' in x\n",
    "    else 'marketing' if 'media' in x \n",
    "    else 'banking' if 'insurance' in x\n",
    "    else 'transportation' if 'transportation' in x\n",
    "    else 'telecommunication' if 'telecommunications' in x\n",
    "    else 'mining' if 'mining' in x\n",
    "    else 'agriculture' if 'agriculture' in x\n",
    "    else 'travel' if 'travel' in x\n",
    "    else 'government' if 'non-profit' in x\n",
    "    else 'entertainment' if 'entertainment' in x\n",
    "    else 'civil' if 'construction' in x\n",
    "    else 'banking' if 'accounting' in x\n",
    "    else 'unknown' if '-1' in x\n",
    "    else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39214dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df['index'] = df.index\n",
    "df = df[['index', 'Job Title', 'company_txt', 'Location', 'job_title_category', 'experience', 'sector_category', 'Degree', 'skills', 'Size']]\n",
    "df.to_csv('stage.csv', index=False)\n",
    "print(df['index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91431b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = df[['index', 'experience', 'skills']]\n",
    "previous_job_df = df[['index', 'experience', 'job_title_category']]\n",
    "industry_df = df[['index', 'experience', 'sector_category']]\n",
    "degree_df = df[['index', 'experience', 'Degree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd516846",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = skills_df.explode('skills')\n",
    "degree_df = degree_df.explode('Degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93acb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = pd.get_dummies(skills_df, columns=['skills'], prefix='col_')\n",
    "skills_df = skills_df.groupby(['index', 'experience']).sum().reset_index()\n",
    "skills_df.to_csv('skills_df.csv', index=False)\n",
    "print(skills_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ee41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_df = pd.get_dummies(degree_df, columns=['Degree'], prefix='col_')\n",
    "degree_df = degree_df.groupby(['index', 'experience']).sum().reset_index()\n",
    "degree_df.to_csv('degree_df.csv', index=False)\n",
    "print(degree_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_job_df = pd.get_dummies(previous_job_df, columns=['job_title_category'], prefix='col_')\n",
    "previous_job_df = previous_job_df.groupby(['index', 'experience']).sum().reset_index()\n",
    "previous_job_df.to_csv('previous_job_df.csv', index=False)\n",
    "print(previous_job_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_df = pd.get_dummies(industry_df, columns=['sector_category'], prefix='col_')\n",
    "industry_df = industry_df.groupby(['index', 'experience']).sum().reset_index()\n",
    "industry_df.to_csv('industry_df.csv', index=False)\n",
    "print(industry_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc046ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df = salary_df.drop(['Job Title', 'Salary Estimate', 'Job Description', 'Company Name', 'Headquarters', \n",
    "                            'Type of ownership', 'Industry', 'Sector', 'Competitors', 'Hourly','Employer provided', \n",
    "                            'Lower Salary', 'Upper Salary', 'company_txt', 'Job Location', \n",
    "                            'Founded', 'Rating', 'Age', 'Revenue', 'skill_len'], axis=1).reset_index()\n",
    "temp = salary_df.copy()\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df['Size'].value_counts()\n",
    "salary_df = salary_df[salary_df['Size'] != 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df['Size'] = salary_df['Size'].apply(lambda x: \n",
    "                                    1 if 'Jan-50' in x else 1 if '51 - 200' in x\n",
    "                                    else 2 if '201 - 500' in x else 3 if '501 - 1000' in x\n",
    "                                    else 4 if '1001 - 5000' in x else 5 if '5001 - 10000' in x else 6)\n",
    "salary_df['Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70937a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df['city'] = salary_df['Location'].apply(lambda x: x.split(',')[0])\n",
    "salary_df['state'] = salary_df['Location'].apply(lambda x: x.split(',')[1])\n",
    "salary_df.drop(['Location'], axis=1, inplace=True)\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b429fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df['salary'] = 0.87 * salary_df['Avg Salary(K)']\n",
    "salary_df.drop(['Avg Salary(K)'], axis=1, inplace=True)\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_of_living_df = pd.read_csv('cost_of_living.csv')\n",
    "cost_of_living_df = cost_of_living_df[['city', 'state', 'cost_of_living']]\n",
    "cost_of_living_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e05c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df = salary_df.merge(cost_of_living_df, how='left', on=['city', 'state'])\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe437c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1094bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df['cost_of_living'] = salary_df['cost_of_living'].fillna(salary_df.groupby(['state'])['cost_of_living'].transform('mean'))\n",
    "mean_cost_of_living = np.mean(salary_df['cost_of_living'])\n",
    "cost_of_living_state = salary_df[['state', 'cost_of_living']]\n",
    "cost_of_living_state = cost_of_living_state.dropna()\n",
    "cost_of_living_state = cost_of_living_state.groupby(['state']).agg(mean_val = ('cost_of_living', 'mean')).reset_index()\n",
    "cost_of_living_state = cost_of_living_state.set_index('state').T.to_dict('records')[0]\n",
    "cost_of_living_state['all'] = mean_cost_of_living\n",
    "salary_df['cost_of_living'] = salary_df['cost_of_living'].fillna(np.mean(salary_df['cost_of_living']))\n",
    "salary_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ae063",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df = salary_df.drop(['city', 'state'], axis=1)\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_encode_df = salary_df[['index', 'skills']]\n",
    "degree_encode_df = salary_df[['index', 'Degree']]\n",
    "salary_df = salary_df.drop(['skills', 'Degree'], axis=1)\n",
    "skills_encode_df = skills_encode_df.explode('skills')\n",
    "degree_encode_df = degree_encode_df.explode('Degree')\n",
    "skills_encode_df = pd.get_dummies(skills_encode_df, columns=['skills'], prefix='col_', drop_first=True)\n",
    "degree_encode_df = pd.get_dummies(degree_encode_df, columns=['Degree'], prefix='col_', drop_first=True)\n",
    "skills_encode_df = skills_encode_df.groupby(['index']).sum().reset_index()\n",
    "degree_encode_df = degree_encode_df.groupby(['index']).sum().reset_index()\n",
    "salary_df = salary_df.merge(skills_encode_df, how='inner', on='index')\n",
    "salary_df = salary_df.merge(degree_encode_df, how='inner', on='index')\n",
    "salary_df = pd.get_dummies(salary_df, columns=['job_title_category', 'experience'], prefix='col_', drop_first=True)\n",
    "print(salary_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salary_df.drop(['salary'], axis=1)\n",
    "Y = salary_df['salary']\n",
    "X_skill = X[skills_encode_df.columns]\n",
    "X_skill = X_skill.drop(['index'], axis=1)\n",
    "X_skill = X_skill.to_numpy()\n",
    "tsvd = TruncatedSVD(n_components=3, random_state=0)\n",
    "W = tsvd.fit_transform(X_skill)\n",
    "print(W.shape)\n",
    "for i in range(W.shape[1]):\n",
    "    col = 'skill_' + str(i)\n",
    "    X[col] = W[:, i]\n",
    "X = X.drop(skills_encode_df.columns, axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07668b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb = XGBRegressor(n_estimators=650, learning_rate=0.1, subsample=0.75, max_depth=7)\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=0)\n",
    "scores = cross_val_score(results_xgb, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "scores = abs(scores)\n",
    "print('Mean MAE and Std from CV: %.3f (%.3f)' % (scores.mean(), scores.std()))\n",
    "results_xgb = XGBRegressor(n_estimators=650, learning_rate=0.1, subsample=0.75, max_depth=7).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e250e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data = ResumeParser('Aditya_Srivastava_Resume.pdf').get_extracted_data()\n",
    "print(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39659f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = 'Unknown'\n",
    "if resume_data['total_experience'] <= 2:\n",
    "    experience = 'Entry'\n",
    "elif resume_data['total_experience'] < 5:\n",
    "    experience = 'Mid'\n",
    "else:\n",
    "    experience = 'Senior'\n",
    "    \n",
    "if not resume_data['degree']:\n",
    "    education_level = ['B']\n",
    "else:\n",
    "    degrees = [x.lower() for x in resume_data['degree']]\n",
    "    education_level = ['B']\n",
    "    for degree in degrees:\n",
    "        if 'phd' in degree:\n",
    "            education_level = ['B', 'M', 'P']\n",
    "            break\n",
    "        elif 'postdoc' in degree:\n",
    "            education_level = ['B', 'M', 'P']\n",
    "            break\n",
    "        elif 'master' in degree:\n",
    "            education_level = ['B', 'M']\n",
    "        elif 'masters' in degree:\n",
    "            education_level = ['B', 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414bea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_job_title, skills, sectors = set(), set(), set()\n",
    "pdfFileObj = open('Aditya_Srivastava_Resume.pdf', 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "pageObj = pdfReader.getPage(0)\n",
    "corpus = pageObj.extractText()\n",
    "pdfFileObj.close()\n",
    "text = corpus.lower()\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "text = tokenizer.tokenize(text)\n",
    "for word in text:\n",
    "        if word in skills_stack_overflow:\n",
    "            skills.add(word)\n",
    "        if word in sectors_dict:\n",
    "            sectors.add(sectors_dict[word])\n",
    "bigrams = list(map(' '.join, nltk.everygrams(text, 2, 2)))\n",
    "bigrams = [x.replace(' ', '') for x in bigrams]\n",
    "for bigram in bigrams:\n",
    "    if bigram in skills_stack_overflow:\n",
    "        skills.add(bigram)\n",
    "    if bigram in sectors_dict:\n",
    "        sectors.add(bigram)\n",
    "    elif bigram == 'dataanalyst' or bigram == 'businessanalyst':\n",
    "        previous_job_title.add('data_analyst')\n",
    "    elif bigram == 'dataengineer' or bigram == 'businessintelligence':\n",
    "        previous_job_title.add('data_engineer')\n",
    "    elif bigram == 'datascientist':\n",
    "        previous_job_title.add('data_scientist')\n",
    "    elif bigram == 'learningengineer' or bigram == 'mlengineer':\n",
    "        previous_job_title.add('ml_engineer')\n",
    "if len(previous_job_title) == 0:\n",
    "    previous_job_title.add('unknown')\n",
    "if len(sectors) == 0:\n",
    "    sectors.add('informationtechnology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfa12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Job titles:', previous_job_title)\n",
    "print('Skills:', skills)\n",
    "print('Sectors:', sectors)\n",
    "print('Experience level:', experience)\n",
    "print('Education level:', education_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d034895",
   "metadata": {},
   "outputs": [],
   "source": [
    "if experience != 'Unknown':\n",
    "    skills_df = skills_df[skills_df['experience'] == experience]\n",
    "    previous_job_df = previous_job_df[previous_job_df['experience'] == experience]\n",
    "    industry_df = industry_df[industry_df['experience'] == experience]\n",
    "    degree_df = degree_df[degree_df['experience'] == experience]\n",
    "index_map = skills_df.index\n",
    "print(skills_df.shape)\n",
    "print(index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdc522",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(1, 3))\n",
    "student_experience_df = pd.DataFrame(data, columns=['col__Mid', 'col__Senior', 'col__Unknown'])\n",
    "if experience != 'Entry':\n",
    "    experience_str = 'col__' + experience\n",
    "    student_experience_df[experience_str] = 1.0\n",
    "student_experience_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(1, len(skills_df.columns)))\n",
    "student_skills_df = pd.DataFrame(data, columns=skills_df.columns)\n",
    "student_skills_df = student_skills_df.drop(['index', 'experience'], axis=1)\n",
    "skills_list = list(skills)\n",
    "skills_list = ['col__' + skill for skill in skills_list]\n",
    "student_skills_df[skills_list] = 1\n",
    "student_skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ce0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(1, len(skills_df.columns)))\n",
    "student_skills_df = pd.DataFrame(data, columns=skills_df.columns)\n",
    "student_skills_df = student_skills_df.drop(['index', 'experience'], axis=1)\n",
    "skills_list = list(skills)\n",
    "skills_list = ['col__' + skill for skill in skills_list]\n",
    "student_skills_df[skills_list] = 1\n",
    "student_skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(1, len(previous_job_df.columns)))\n",
    "student_previous_job_df = pd.DataFrame(data, columns=previous_job_df.columns)\n",
    "student_previous_job_df = student_previous_job_df.drop(['index', 'experience'], axis=1)\n",
    "previous_job_list = list(previous_job_title)\n",
    "previous_job_list = ['col__' + previous_job for previous_job in previous_job_list]\n",
    "student_previous_job_df[previous_job_list] = 1\n",
    "student_previous_job_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011bc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(1, len(industry_df.columns)))\n",
    "student_industry_df = pd.DataFrame(data, columns=industry_df.columns)\n",
    "student_industry_df = student_industry_df.drop(['index', 'experience'], axis=1)\n",
    "sectors_list = list(sectors)\n",
    "sectors_list = ['col__' + sector for sector in sectors_list]\n",
    "student_industry_df[sectors_list] = 1\n",
    "student_industry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadf3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(1, len(degree_df.columns)))\n",
    "student_degree_df = pd.DataFrame(data, columns=degree_df.columns)\n",
    "student_degree_df = student_degree_df.drop(['index', 'experience'], axis=1)\n",
    "degree_list = list(education_level)\n",
    "degree_list = ['col__' + degree for degree in degree_list]\n",
    "student_degree_df[degree_list] = 1\n",
    "student_degree_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_ndarray(df1, df2):\n",
    "    a = df1.drop(['index', 'experience'], axis=1)\n",
    "    a = a.to_numpy()\n",
    "    b = df2.to_numpy()\n",
    "    return a, b\n",
    "\n",
    "def cosine_similarity(A,B):\n",
    "    num = np.dot(A,B.T)\n",
    "    p1 = np.sqrt(np.sum(A**2,axis=1))[:,np.newaxis]\n",
    "    p2 = np.sqrt(np.sum(B**2,axis=1))[np.newaxis,:]\n",
    "    return num / (p1 * p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = dataframe_to_ndarray(skills_df, student_skills_df)\n",
    "skill_match_arr = cosine_similarity(A, B)\n",
    "A, B = dataframe_to_ndarray(previous_job_df, student_previous_job_df)\n",
    "title_match_arr = cosine_similarity(A, B)\n",
    "A, B = dataframe_to_ndarray(industry_df, student_industry_df)\n",
    "industry_match_arr = cosine_similarity(A, B)\n",
    "A, B = dataframe_to_ndarray(degree_df, student_degree_df)\n",
    "degree_match_arr = cosine_similarity(A, B)\n",
    "print('Skills match:', np.argmax(skill_match_arr), np.max(skill_match_arr))\n",
    "print('Title match:', np.argmax(title_match_arr), np.max(title_match_arr))\n",
    "print('Industry match:', np.argmax(industry_match_arr), np.max(industry_match_arr))\n",
    "print('Degree match:', np.argmax(degree_match_arr), np.max(degree_match_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_arr = np.concatenate((skill_match_arr, title_match_arr, industry_match_arr, degree_match_arr), axis=1)\n",
    "minmax_scaler = MinMaxScaler()\n",
    "results_arr = minmax_scaler.fit_transform(results_arr)\n",
    "weighted_arr = np.array([0.5, 0.2, 0.15, 0.15])[:, np.newaxis]\n",
    "score_arr = np.matmul(results_arr, weighted_arr)\n",
    "buffer = np.argsort(score_arr, axis=0)[-10:-1].flatten()\n",
    "company_recommendations = {}\n",
    "company_recommendations[df['company_txt'][index_map[np.argmax(score_arr)]]] = np.argmax(score_arr)\n",
    "for i in range(len(buffer) - 1, -1, -1):\n",
    "    company_recommendations[df['company_txt'][index_map[buffer[i]]]] = buffer[i]\n",
    "    if len(company_recommendations) == 3:\n",
    "        break\n",
    "print(company_recommendations.values(), np.max(score_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_previous_job_df = student_previous_job_df.replace(1.0, 0.0)\n",
    "student_df = pd.DataFrame()\n",
    "company_size, cost_of_living = [], []\n",
    "for match in company_recommendations.values():\n",
    "    company_size.append(df['Size'][index_map[match]])\n",
    "    city = df['Location'][index_map[match]].split(',')[0]\n",
    "    state = df['Location'][index_map[match]].split(',')[1]\n",
    "    cost_of_living_val = cost_of_living_df[(cost_of_living_df['city'] == city) & (cost_of_living_df['state'] == state)]['cost_of_living'].values\n",
    "    if len(cost_of_living_val) != 0:\n",
    "        cost_of_living_val = cost_of_living_val[0]\n",
    "    else:\n",
    "        if state in cost_of_living_state:\n",
    "            cost_of_living_val = cost_of_living_state[state]\n",
    "        else:\n",
    "            cost_of_living_val = cost_of_living_state['all']\n",
    "    cost_of_living.append(cost_of_living_val)\n",
    "    job_title = df['job_title_category'][index_map[match]]\n",
    "    student_previous_job_df['col__' + job_title] = 1.0\n",
    "company_size = [1 if 'Jan-50' in x else 1 if '51 - 200' in x\n",
    "                                    else 2 if '201 - 500' in x else 3 if '501 - 1000' in x\n",
    "                                    else 4 if '1001 - 5000' in x else 5 if '5001 - 10000' in x else 6 for x in company_size]\n",
    "student_df['Size'] = company_size\n",
    "student_df['cost_of_living'] = cost_of_living\n",
    "\n",
    "temp = pd.concat([student_degree_df.iloc[: , 1:], student_previous_job_df.iloc[: , 1:], student_experience_df, student_skills_df.iloc[: , 1:]], axis=1)\n",
    "temp = temp.append([temp] * (len(company_recommendations) - 1), ignore_index=True)\n",
    "student_df = pd.concat([student_df, temp], axis=1)\n",
    "student_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe33773",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_columns = list(student_skills_df.columns)\n",
    "skill_columns.pop(0)\n",
    "X_student = student_df[skill_columns]\n",
    "W_student = tsvd.transform(X_student)\n",
    "print(W.shape)\n",
    "for i in range(W_student.shape[1]):\n",
    "    col = 'skill_' + str(i)\n",
    "    student_df[col] = W_student[:, i]\n",
    "student_df = student_df.drop(skill_columns, axis=1)\n",
    "student_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd871c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_pred = results_xgb.predict(student_df)\n",
    "print(salary_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ca021",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = []\n",
    "for idx, match in enumerate(company_recommendations.values()):\n",
    "    components = {}\n",
    "    components['company'] = df['company_txt'][index_map[match]]\n",
    "    components['job_title'] = df['Job Title'][index_map[match]]\n",
    "    components['location'] = df['Location'][index_map[match]]\n",
    "    components['salary'] = salary_pred[idx]\n",
    "    recommendations.append(components)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salary_df['Revenue'].value_counts()\n",
    "# salary_df['Revenue'] = salary_df['Revenue'].apply(lambda x: 1 if 'Less than $1 million' in x else 1 if '$1 to $5 million' in x\n",
    "#                                       else 1 if '$5 to $10 million' in x else 2 if '$10 to $25 million' in x\n",
    "#                                       else 2 if '$25 to $50 million' in x else 2 if '$50 to $100 million' in x\n",
    "#                                       else 3 if '$100 to $500 million' in x else 4 if '$500 million to $1 billion' in x\n",
    "#                                       else 0 if 'Unknown' in x else 5)\n",
    "# salary_df['Revenue'][salary_df['Revenue'] == 0] = salary_df['Size']\n",
    "# salary_df['Revenue'][salary_df['Revenue'] > 5] = 5\n",
    "# salary_df['Revenue'].value_counts()\n",
    "# salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salary_df['Rating'] = salary_df['Rating'].apply(lambda x: 1 if x < 3 else 2 if x < 4 else 3)\n",
    "# salary_df['Rating'].value_counts()\n",
    "# salary_df['Age'] = salary_df['Age'].apply(lambda x: 1 if x < 5 else 2 if x < 10 else 3 if x < 15 else 4 if x < 20 else 5)\n",
    "# salary_df['tech_hub'] = salary_df['tech_hub'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills_str = \" \".join(skills_encode_df.columns)\n",
    "# salary_df.to_csv('salary_input.csv', index=False)\n",
    "# f = open('skills_encoded.txt', 'w')\n",
    "# f.write(skills_str)\n",
    "# f.close()\n",
    "# salary_df = pd.read_csv('salary_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = salary_df.drop(['salary'], axis=1)\n",
    "# Y = salary_df['salary']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "# print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_skill = X_train[skills_encode_df.columns]\n",
    "# X_train_skill = X_train_skill.drop(['index'], axis=1)\n",
    "# X_test_skill = X_test[skills_encode_df.columns]\n",
    "# X_test_skill = X_test_skill.drop(['index'], axis=1)\n",
    "# print(X_train_skill.shape)\n",
    "# X_train_skill = X_train_skill.to_numpy()\n",
    "# tsvd = TruncatedSVD(n_components=3, random_state=0)\n",
    "# W = tsvd.fit_transform(X_train_skill)\n",
    "# W_test = tsvd.transform(X_test_skill)\n",
    "# print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe66f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(W.shape[1]):\n",
    "#     col = 'skill_' + str(i)\n",
    "#     X_train[col] = W[:, i]\n",
    "#     X_test[col] = W_test[:, i]\n",
    "# X_train = X_train.drop(skills_encode_df.columns, axis=1)\n",
    "# X_test = X_test.drop(skills_encode_df.columns, axis=1)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d982b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([X_train, y_train], axis=1)\n",
    "# test_df = pd.concat([X_test, y_test], axis=1)\n",
    "# train_df.to_csv('train.csv', index=False)\n",
    "# test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a371ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('train.csv')\n",
    "# test_df = pd.read_csv('test.csv')\n",
    "# X_train = train_df.drop(['salary'], axis=1)\n",
    "# y_train = train_df['salary']\n",
    "# X_test = test_df.drop(['salary'], axis=1)\n",
    "# y_test = test_df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_LR = sm.add_constant(X_train)\n",
    "# results_lr = sm.OLS(y_train, X_train_LR).fit()\n",
    "# # print(results_lr.summary())\n",
    "# X_test_LR = sm.add_constant(X_test)\n",
    "# y_pred_LR = results_lr.predict(X_test_LR)\n",
    "# mae = mean_absolute_error(y_test, y_pred_LR)\n",
    "# print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_rf = RandomForestRegressor(random_state=0)\n",
    "# cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "# scores = cross_val_score(results_rf, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# scores = abs(scores)\n",
    "# print('Mean MAE and Std from CV: %.3f (%.3f)' % (scores.mean(), scores.std()))\n",
    "# results_rf = RandomForestRegressor(random_state=0).fit(X_train, y_train)\n",
    "# y_pred_RF = results_rf.predict(X_test)\n",
    "# mae = mean_absolute_error(y_test, y_pred_RF)\n",
    "# print('MAE from test:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance = results_rf.feature_importances_\n",
    "# for i,v in enumerate(importance):\n",
    "#     print(f'Feature: {X_train.columns[i]}, Score: {v}')\n",
    "# plt.bar([x for x in range(len(importance))], importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def xgb_regress(max_depth, n_estimators, learning_rate, subsample):\n",
    "#     params_gbm = {}\n",
    "#     params_gbm['max_depth'] = round(max_depth)\n",
    "#     params_gbm['n_estimators'] = round(n_estimators)\n",
    "#     params_gbm['learning_rate'] = learning_rate\n",
    "#     params_gbm['subsample'] = subsample\n",
    "#     scores = cross_val_score(GradientBoostingRegressor(random_state=0, **params_gbm),\n",
    "#                              X, Y, scoring='neg_mean_absolute_error', cv=5)\n",
    "#     return -np.mean(abs(scores))\n",
    "\n",
    "# start = time.time()\n",
    "# params_gbm ={\n",
    "#     'max_depth':(6, 8),\n",
    "#     'n_estimators':(400, 700),\n",
    "#     'learning_rate':(0.05, 0.1),\n",
    "#     'subsample':(0.7, 0.9)\n",
    "# }\n",
    "# gbm_bo = BayesianOptimization(xgb_regress, params_gbm, random_state=0)\n",
    "# gbm_bo.maximize(init_points=20, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_xgb = XGBRegressor(n_estimators=600, learning_rate=0.1, subsample=0.7, max_depth=7)\n",
    "# cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=0)\n",
    "# scores = cross_val_score(results_xgb, X_train_shrinked, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# scores = abs(scores)\n",
    "# print('Mean MAE and Std from CV: %.3f (%.3f)' % (scores.mean(), scores.std()))\n",
    "# results_xgb = XGBRegressor(random_state=0).fit(X_train_shrinked, y_train)\n",
    "# y_pred_XGB = results_xgb.predict(X_test_shrinked)\n",
    "# mae = mean_absolute_error(y_test, y_pred_XGB)\n",
    "# print('MAE from test:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee21e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance = results_xgb.feature_importances_\n",
    "# for i,v in enumerate(importance):\n",
    "#     print(f'Feature: {X_train_shrinked.columns[i]}, Score: {v}')\n",
    "# plt.bar([x for x in range(len(importance))], importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
